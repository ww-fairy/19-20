1. Model-Free RL 和 Model-Based RL 区别

   1. 概念
   2. 想象力

2. 基于概率 Policy-Based RL and 基于价值 Value-Based RL

   1. 基于概率 Policy-Based ，每种方法都可能选中 、 基于概率连续概率分布
      1. Policy Gradients
   2. 基于价值 输出价值最高的 、 连续动作无能为力
      1. Q learning 、Sarsa
   3. 更牛逼的方法 Actor-Critic 
      1. 基于概率给出动作，再给出此动作价值，原有Policy上加速学习过程

3. (回合更新)Monte-Carlo update  and (单步更新)Temporal-Difference update 

   ​	1.游戏开始结束 （policy gradients mote-carlo learning）

   ​	2. 边玩边学习	（Q learning Sarsa Actor-Critic）

4. On-Policy 在线学习、 Off-Policy 离线学习

   1. 自己玩 Sarsa Sarsa($\lambda$)
   2. 看着别人玩   Q-learning Deep Q Network

